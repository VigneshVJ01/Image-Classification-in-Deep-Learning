# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15a81JNuL6xZH29LBTHYANhhhhZRj3cV8
"""

from google.colab import files
uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json
#

# The following print statement was causing the IndentationError
# It was indented an extra level and should be aligned with the for loop
print('User uploaded file "{name}" with length {length} bytes'.format(
    name=fn, length=len(uploaded[fn])))

# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json
#

!kaggle datasets download -d navoneel/brain-mri-images-for-brain-tumor-detection

import tensorflow as tf
from zipfile import ZipFile
import os, glob
import cv2
from tqdm._tqdm_notebook import tqdm_notebook as tqdm
import numpy as np
import sklearn
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Conv2D, Dropout, Dense, MaxPooling2D, Flatten
from keras.layers import BatchNormalization

from zipfile import ZipFile
file_name = "/content/brain-mri-images-for-brain-tumor-detection.zip"

with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('Done')

# Process 'yes' directory
os.chdir('/content/yes')
x = []
y = []
for i in tqdm(os.listdir()):
  img = cv2.imread(i)
  img = cv2.resize(img, (224,224))
  x.append(img)
  y.append(i[0:1])
  print(i[0:1])

# Change to the 'no' directory using os.chdir
os.chdir('/content/no') # Use os.chdir to change directory
for i in tqdm(os.listdir()):
  img = cv2.imread(i)
  img = cv2.resize(img, (224,224))
  x.append(img)

# Append labels for 'no' images
for i in range(len(os.listdir())): # Iterate based on number of images in 'no' directory
  y.append('N') # Append label 'N' for 'no' images
  print(y)

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for i in range(4):
  plt.subplot(1, 4, i+1)
  plt.imshow(x[i], cmap="gray")
  plt.axis('off')
  plt.show()

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)
print ("Shape of an image in x_train: ", x_train[0].shape)
print ("Shape of an image in x_test: ", x_test[0].shape)

import sklearn.preprocessing
from sklearn.preprocessing import LabelEncoder # Correct import statement

le = LabelEncoder() # Corrected attribute name
y_train = le.fit_transform(y_train)
y_test = le.fit_transform(y_test)
y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)
y_train = np.array(y_train)
x_train = np.array(x_train)
y_test = np.array(y_test)
x_test = np.array(x_test)

print("x_train Shape: ", x_train.shape)
print("y_train Shape: ", y_train.shape)
print("x_test Shape: ", x_test.shape)
print("y_test Shape: ", y_test.shape)

from keras.applications import vgg16

img_rows, img_cols = 224, 224


vgg = vgg16.VGG16(weights = 'imagenet',
                  include_top = False,
                  input_shape = (img_rows, img_cols, 3))

# Here we freeze the last 4 layers
# layers are set to trainable as true by default
for layer in vgg.layers: # Changed 'vegg' to 'vgg'
  layer.trainable = False

# Let's print our layers
for (i, layer) in enumerate(vgg.layers):
  print(str(i) + " "+ layer.__class__.__name__, layer.trainable)

from ast import Global
def lw(bottom_model, num_classses):
  """creates the top or head of the model that will be
  placed ontop of the bottom layers"""

  top_model = bottom_model.output
  top_model = GlobalAveragePooling2D()(top_model)
  top_model = Dense(1024, activation='relu')(top_model)
  top_model = Dense(1024, activation='relu')(top_model)
  top_model = Dense(512, activation='relu')(top_model)
  top_model = Dense(num_classes, activation='softmax')(top_model)
  return top_model

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D

from keras.models import Model


num_classes = 2
FC_Head = lw(vgg, num_classes)

model = Model(inputs = vgg.input, outputs = FC_Head)

print(model.summary())

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(x_train, y_train,
                    epochs=5,
                    validation_data=(x_test, y_test),
                    verbose = 1, # Changed 'verbos' to 'verbose'
                    initial_epoch=0)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()

plt.show()

from google.colab import drive
drive.mount('/content/drive')